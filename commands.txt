1) kafka docker

docker run --rm -it -p 2181:2181 -p 3030:3030 -p 8081:8081 -p 8082:8082 -p 8083:8083 -p 9092:9092 -e ADV_HOST=192.168.99.100 landoop/fast-data-dev

kafka command line tools

docker run --rm -it --net=host landoop/fast-data-dev bash

create kafka topics
kafka-topics --zookeeper 192.168.99.100:2181 --create --topic movie_users_mapping --partitions 3 --replication-factor 1
kafka-topics --zookeeper 192.168.99.100:2181 --create --topic movie_ratings --partitions 3 --replication-factor 1


2) MongoDB

winpty docker exec -it mongodb bash

use movie_analysis

db.createUser({user:"admin", pwd:"admin", roles:["readWrite", "dbAdmin"]});

https://blog.jeremylikness.com/mongodb-on-windows-in-minutes-with-docker-3e412f076762

 mongo --host mongodb://admin:admin@192.168.99.100:27017/movie_analysis


3) First time node install
- npm install
- npm i babel-cli -g
- npm i nodemon -g

After installation
- goto main folder ./movie-trailer-bigdata
  run command nodemon

instructions to run kafka consumer
- goto kafka folder
- run babel-node consumer.js

3) Spark

Steps to run spark job

spark-submit --master local[*] --conf "spark.mongodb.input.uri=mongodb://192.168.99.100/movie_analysis" --conf "spark.mongodb.output.uri=mongodb://192.168.99.100/movie_analysis" --packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 trending.py 